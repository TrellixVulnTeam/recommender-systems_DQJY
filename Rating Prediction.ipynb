{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD, SVDpp, KNNBasic, BaselineOnly, NormalPredictor\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV, KFold, cross_validate, train_test_split\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userID  itemID  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "\n",
      "\n",
      "\n",
      "   userID  itemID  rating  timeStamp\n",
      "0       5     648       5  978297876\n",
      "1       5    1394       5  978298237\n",
      "2       5    3534       5  978297149\n",
      "3       5     104       4  978298558\n",
      "4       5    2735       5  978297919\n"
     ]
    }
   ],
   "source": [
    "# Read both the datasets from the files using pandas\n",
    "movielens_df = pd.read_csv(\"data/u.data\", sep=\"\\t\", header=None)\n",
    "movielens_df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    "pda_df = pd.read_csv(\"data/train-PDA2018.csv\", sep=\",\")\n",
    "print(movielens_df.head())\n",
    "print(\"\\n\\n\")\n",
    "print(pda_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information on the training sets we will be using \n",
      "\n",
      "1) Number of items in each dataset  ML100k: 1651 PDA: 1819\n",
      "2) Number of users in each dataset  ML100k: 943 PDA: 5684\n",
      "3) Number of ratings in each dataset  ML100k: 80000 PDA: 376568\n",
      "4) Mean rating  ML100k: 3.5290875 PDA: 3.637212933653417\n"
     ]
    }
   ],
   "source": [
    "# Create the training datasets using Surprise's reader class\n",
    "reader = Reader(rating_scale=(1,5)) # We have ratings from 1 to 5 so we create the rating scale\n",
    "\n",
    "# Load the data from the dataframes\n",
    "movielens_dataset = Dataset.load_from_df(movielens_df.iloc[:,0:3], reader)\n",
    "pda_dataset = Dataset.load_from_df(pda_df.iloc[:,0:3], reader)\n",
    "\n",
    "# Build train-test sets from the data loaded above\n",
    "mls_train, mls_test = train_test_split(movielens_dataset, test_size=.20, random_state=0)\n",
    "pda_train, pda_test = train_test_split(pda_dataset, test_size=.20, random_state=0)\n",
    "\n",
    "# Print out some basic information about the datasets\n",
    "print(\"General information on the training sets we will be using \\n\")\n",
    "print(\"1) Number of items in each dataset\", \" ML100k:\", mls_train.n_items, \"PDA:\", pda_train.n_items)\n",
    "print(\"2) Number of users in each dataset\", \" ML100k:\", mls_train.n_users, \"PDA:\", pda_train.n_users)\n",
    "print(\"3) Number of ratings in each dataset\", \" ML100k:\", mls_train.n_ratings, \"PDA:\", pda_train.n_ratings)\n",
    "print(\"4) Mean rating\", \" ML100k:\", mls_train.global_mean, \"PDA:\", pda_train.global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search and 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable declarations: the 5 fold split and a list that will contain the results of the cross validation procedure\n",
    "results_table = []\n",
    "best_params = {}\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for the Random (NormalPredictor) algorithm...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running grid search for the Random (NormalPredictor) algorithm...\")\n",
    "out = cross_validate(NormalPredictor(), movielens_dataset, [\"rmse\", \"mae\"], kf)\n",
    "mean_rmse = '{:.3f}.'.format(np.mean(out['test_rmse']))\n",
    "mean_mae = '{:.3f}.'.format(np.mean(out['test_mae']))\n",
    "new_line = [\"Random\", mean_rmse, mean_mae]\n",
    "results_table.append(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for the BaselineOnly algorithm...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "\n",
      "Results:\n",
      "Best RMSE: 0.9413120311280998\n",
      "Best params for RMSE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "Best MAE: 0.7434442260666927\n",
      "Best params for MAE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run grid search in order to check for parameters that will allow for optimal RMSE and MAE\n",
    "# Define the parameters and their respective ranges\n",
    "param_grid = {\n",
    "    \"bsl_options\": {\n",
    "        \"method\": [\"als\", \"sgd\"],\n",
    "        \"reg\": [0.01, 0.5], \n",
    "        \"n_epochs\": [5,20]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run grid search for the specified algorithm and the parameter grid\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=5) # 5-fold CV\n",
    "print(\"Running grid search for the BaselineOnly algorithm...\")\n",
    "# Fit the data to the model using the parameters of the grid search\n",
    "gs.fit(movielens_dataset)\n",
    "# Save the best parameters of the models and the best scores\n",
    "best_params[\"BaselineRMSE\"] = gs.best_params[\"rmse\"]\n",
    "best_params[\"BaselineMAE\"] = gs.best_params[\"mae\"]\n",
    "results_table.append([\"Baseline\", '{:.3f}.'.format(gs.best_score[\"rmse\"]), '{:.3f}.'.format(gs.best_score[\"mae\"])])\n",
    "# Print out the the best RMSE, MAE and the respective model parameters\n",
    "print(\"\\nResults:\")\n",
    "print(\"Best RMSE:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params for RMSE\", gs.best_params[\"rmse\"])\n",
    "print(\"Best MAE:\", gs.best_score[\"mae\"])\n",
    "print(\"Best params for MAE\", gs.best_params[\"mae\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN CF algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for KNN\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Results:\n",
      "Best RMSE: 0.9806908097705838\n",
      "Best params for RMSE {'k': 50, 'min_k': 1}\n",
      "Best MAE: 0.775065617118536\n",
      "Best params for MAE {'k': 50, 'min_k': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a dict of recommender algorithms we wish to do the grid search for\n",
    "ub_options = {'name': 'cosine', 'user_based': True}\n",
    "ib_options = {'name': 'cosine', 'user_based': False}\n",
    "knn_options = {\"ubKNN\": ub_options , \"ibKNN\": ib_options}\n",
    "knn_algorithms = {\"ubKNN\": KNNBasic(sim_options=ub_options) , \"ibKNN\": KNNBasic(sim_options=ib_options)}\n",
    "\n",
    "param_grid = {\n",
    "    \"k\": [5,50],\n",
    "    \"min_k\": [1, 5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=5) # 5-fold CV\n",
    "print(\"Running grid search for KNN\")\n",
    "gs.fit(movielens_dataset)\n",
    "# Save the best parameters of the models and the best scores\n",
    "best_params[\"knnRMSE\"] = gs.best_params[\"rmse\"]\n",
    "best_params[\"knnMAE\"] = gs.best_params[\"mae\"]\n",
    "# Print out the the best RMSE, MAE and the respective model parameters\n",
    "print(\"\\nResults:\")\n",
    "print(\"Best RMSE:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params for RMSE\", gs.best_params[\"rmse\"])\n",
    "print(\"Best MAE:\", gs.best_score[\"mae\"])\n",
    "print(\"Best params for MAE\", gs.best_params[\"mae\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Run 5 fold cross validation to see how the user-based and item-based KNN cf algorithms will perform\n",
    "# We need to do this because we can't separate the two algorithms when using the GridSearchCv function\n",
    "# Hence we run the cross validation for both algorithms manually and then save the respective results\n",
    "knn_titles = (\"ubKNN\", \"ibKNN\")\n",
    "ub_options = {'name': 'cosine', 'user_based': True}\n",
    "ib_options = {'name': 'cosine', 'user_based': False}\n",
    "knn_sim_options = {\"ubKNN\": ub_options , \"ibKNN\": ib_options}\n",
    "\n",
    "fold_n = 0\n",
    "# Run 5 fold cross validation\n",
    "for title in knn_titles:    \n",
    "    out = cross_validate(KNNBasic(k=50, min_k=1, sim_options=knn_sim_options[title]), movielens_dataset, [\"rmse\", \"mae\"], kf)\n",
    "    mean_rmse = '{:.3f}.'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}.'.format(np.mean(out['test_mae']))\n",
    "    new_line = [title, mean_rmse, mean_mae]\n",
    "    results_table.append(new_line)\n",
    "    fold_n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for SVD\n",
      "\n",
      "Results:\n",
      "Best RMSE: 0.9637806074745058\n",
      "Best params for RMSE {'n_epochs': 20, 'lr_all': 0.001, 'reg_all': 0.01}\n",
      "Best MAE: 0.7650417309708972\n",
      "Best params for MAE {'n_epochs': 20, 'lr_all': 0.001, 'reg_all': 0.01}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run grid search in order to check for parameters that will allow for optimal RMSE and MAE\n",
    "# Define the parameters and their respective ranges\n",
    "param_grid = {\n",
    "    \"n_epochs\": [5,20],\n",
    "    \"lr_all\": [0.001, 0.05],\n",
    "    \"reg_all\": [0.01, 0.5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=5) # 5-fold CV\n",
    "print(\"Running grid search for SVD\")\n",
    "gs.fit(movielens_dataset)\n",
    "# Save the best parameters of the models and the best scores\n",
    "best_params[\"svdRMSE\"] = gs.best_params[\"rmse\"]\n",
    "best_params[\"svdMAE\"] = gs.best_params[\"mae\"]\n",
    "results_table.append([\"SVD\", '{:.3f}.'.format(gs.best_score[\"rmse\"]), '{:.3f}.'.format(gs.best_score[\"mae\"])])\n",
    "# Print out the the best RMSE, MAE and the respective model parameters\n",
    "print(\"\\nResults:\")\n",
    "print(\"Best RMSE:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params for RMSE\", gs.best_params[\"rmse\"])\n",
    "print(\"Best MAE:\", gs.best_score[\"mae\"])\n",
    "print(\"Best params for MAE\", gs.best_params[\"mae\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Recommender   | RMSE   | MAE    |\n",
      "|:--------------|:-------|:-------|\n",
      "| Random        | 1.520. | 1.221. |\n",
      "| Baseline      | 0.941. | 0.743. |\n",
      "| ubKNN         | 1.017. | 0.804. |\n",
      "| ibKNN         | 1.023. | 0.809. |\n",
      "| SVD           | 0.964. | 0.765. |\n"
     ]
    }
   ],
   "source": [
    "results_table_headers = [\"Recommender\", \"RMSE\", \"MAE\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
