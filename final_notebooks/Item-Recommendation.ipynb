{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import KFold, cross_validate\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and load the data using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML100K\n",
      "    userID  itemID  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "\n",
      "\n",
      "\n",
      "PDA2018\n",
      "    userID  itemID  rating  timeStamp\n",
      "0       5     648       5  978297876\n",
      "1       5    1394       5  978298237\n",
      "2       5    3534       5  978297149\n",
      "3       5     104       4  978298558\n",
      "4       5    2735       5  978297919\n",
      "Shapes before sub-sampling:\n",
      "(100000, 4)\n",
      "(470711, 4)\n",
      "\n",
      "Shapes after sub-sampling:\n",
      "(97623, 4)\n",
      "(465154, 4)\n",
      "\n",
      " Some general information on the training sets we will be using:\n",
      "1) Number of items in each dataset  ML100k: 1682 PDA: 1824\n",
      "2) Number of users in each dataset  ML100k: 943 PDA: 5690\n",
      "3) Number of ratings in each dataset  ML100k: 100000 PDA: 470711\n",
      "4) Mean rating  ML100k: 3.52986 PDA: 3.638361967321775\n"
     ]
    }
   ],
   "source": [
    "# Read both the datasets from the files using pandas\n",
    "movielens_df = pd.read_csv(\"../data/u.data\", sep=\"\\t\", header=None)\n",
    "movielens_df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    "pda_df = pd.read_csv(\"../data/train-PDA2018.csv\", sep=\",\")\n",
    "print(\"ML100K\\n\", movielens_df.head())\n",
    "print(\"\\n\\n\")\n",
    "print(\"PDA2018\\n\", pda_df.head())\n",
    "\n",
    "# Sample the data such that every user has rated at least 10 items and every item has been by at least 10 users\n",
    "print(\"Shapes before sub-sampling:\")\n",
    "print(movielens_df.shape)\n",
    "print(pda_df.shape)\n",
    "\n",
    "# Movielens users all have at least 20 ratings so no need to subsample the user values\n",
    "ml_subsampled = movielens_df[movielens_df['itemID'].isin(movielens_df['itemID'].value_counts()[movielens_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_df[pda_df['itemID'].isin(pda_df['itemID'].value_counts()[pda_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_subsampled[pda_subsampled['userID'].isin(pda_subsampled['userID'].value_counts()[pda_subsampled['userID'].value_counts()>10].index)]\n",
    "print(\"\\nShapes after sub-sampling:\")\n",
    "print(ml_subsampled.shape)\n",
    "print(pda_subsampled.shape)\n",
    "\n",
    "# Create the training datasets using Surprise's reader class\n",
    "reader = Reader(rating_scale=(1,5)) # We have ratings from 1 to 5 so we create the rating scale\n",
    "\n",
    "# Load the data from the dataframes\n",
    "movielens_dataset = Dataset.load_from_df(movielens_df.iloc[:,0:3], reader)\n",
    "pda_dataset = Dataset.load_from_df(pda_df.iloc[:,0:3], reader)\n",
    "\n",
    "# Build full trainsets to print out the data loaded above\n",
    "mls_train = movielens_dataset.build_full_trainset()\n",
    "pda_train = pda_dataset.build_full_trainset()\n",
    "\n",
    "# Print out some basic information about the datasets\n",
    "print(\"\\n Some general information on the training sets we will be using:\")\n",
    "print(\"1) Number of items in each dataset\", \" ML100k:\", mls_train.n_items, \"PDA:\", pda_train.n_items)\n",
    "print(\"2) Number of users in each dataset\", \" ML100k:\", mls_train.n_users, \"PDA:\", pda_train.n_users)\n",
    "print(\"3) Number of ratings in each dataset\", \" ML100k:\", mls_train.n_ratings, \"PDA:\", pda_train.n_ratings)\n",
    "print(\"4) Mean rating\", \" ML100k:\", mls_train.global_mean, \"PDA:\", pda_train.global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise experiment parameters and variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Define auxilliary functions to get Top-N and then calculate precision and recall in Surprise + more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have ratings in the train set for all the users in the test set\n",
    "def find_items_not_in_trainset(trainset, testset):\n",
    "    items_not_in_train = []\n",
    "    for _,itemId, _ in testset:    \n",
    "        if itemId not in trainset.ir.keys():\n",
    "            items_not_in_train.append(itemId)\n",
    "            \n",
    "    return items_not_in_train\n",
    "\n",
    "        \n",
    "def user_seen_items(userId):\n",
    "    return [train_itemId for train_itemId, rating in mls_train.ur[userId]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n, minimumRating, criterion):\n",
    "    topN = defaultdict(list)\n",
    "    \n",
    "    for index, row in predictions.iterrows():\n",
    "        if (row[criterion] >= minimumRating):\n",
    "            topN[int(row.uid)].append((int(row.iid), row[criterion]))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, items_not_in_train, k, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions, n=k, minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions, n=k, minimumRating=threshold, criterion=\"r_ui\")\n",
    "    above_threshold = predictions[predictions.r_ui >= threshold]\n",
    "\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "\n",
    "    for uid, est_topn in top_n_recoms_est.items():\n",
    "        # Get items the user has already rated\n",
    "        already_seen = user_seen_items(uid)\n",
    "        # Get relevant items for the user\n",
    "        n_rel_for_user = len(above_threshold[above_threshold.uid == uid])        \n",
    "        tp = 0\n",
    "        # Penalize the scores if:\n",
    "        # - The item we are recommending was never seen in the training set (how could we recommend what we don't know?)\n",
    "        # - The user has already rated this item: It's not a good recommendation since the user already knows it/has seen it\n",
    "        for est_itemId, _ in est_topn:\n",
    "            if(est_itemId in items_not_in_train or est_itemId in already_seen):\n",
    "                tp += 0\n",
    "            else:\n",
    "                for real_itemId, _ in top_n_recoms_real[uid]:\n",
    "                    if (est_itemId == real_itemId):\n",
    "                        tp +=1\n",
    "        \n",
    "        precisions[uid] = tp/k\n",
    "        recalls[uid] = tp/n_rel_for_user if n_rel_for_user != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "def ndcg_for_rec(predictions, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"r_ui\")\n",
    "    ndcgs = {}\n",
    "\n",
    "    for uid, real_topn in top_n_recoms_real.items():\n",
    "        user_gt = [true_rating[0] for true_rating in real_topn]\n",
    "        est_top_for_current = top_n_recoms_est[uid]\n",
    "        predicted_items = [est_rating[0] for est_rating in est_top_for_current]\n",
    "        predicted_scores = [est_rating[1] for est_rating in est_top_for_current]\n",
    "        gain_scores = np.zeros(len(user_gt)).tolist()\n",
    "\n",
    "        ndcg_val = 0\n",
    "        \n",
    "        if(len(predicted_items) == 0):\n",
    "            ndcg_val += 0\n",
    "        elif(len(predicted_items) == 1 or len(user_gt) == 1):\n",
    "            if(predicted_items[0] == user_gt[0]):\n",
    "                ndcg_val += 1\n",
    "        else:\n",
    "            for i, pred_item in enumerate(predicted_items):\n",
    "                for j, gt_item in enumerate(user_gt):\n",
    "                    if(gt_item==pred_item):\n",
    "                        gain_scores[j] = i\n",
    "            gain_scores =[int(elem) for elem in gain_scores]\n",
    "            ndcg_val += ndcg_score(np.asarray([user_gt]), np.asarray([gain_scores]))\n",
    "            \n",
    "        #print(\"GT:\", user_gt)\n",
    "        #print(\"Pred:\", predicted_items)\n",
    "        #print(gain_scores)\n",
    "        #print( \"\\n\\n\")\n",
    "        ndcgs[uid] = ndcg_val\n",
    "\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EXPERIMENT VARIABLES\"\"\"\n",
    "# List that will contain the results of all experiments\n",
    "results_table = []\n",
    "kf = KFold(n_splits=5) # define number of k splits for cross validation using Surprise KFold\n",
    "\n",
    "# Algorithms we will be using in this section\n",
    "algorithms = {\n",
    "    \"UserKNN\": KNNWithMeans(k=60, sim_options={'name': 'pearson_baseline', 'shrinkage': 25, 'user_based': True}),\n",
    "    \"ItemKNN\": KNNWithMeans(k=40, sim_options={'name': 'pearson_baseline', 'shrinkage': 25, 'user_based': False}),\n",
    "}\n",
    "# Datasets\n",
    "datasets = {\n",
    "    \"ML100\": movielens_dataset,\n",
    "    \"PDA2018\": pda_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with UserKNN on ML100 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with ItemKNN on ML100 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with UserKNN on PDA2018 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with ItemKNN on PDA2018 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for algorithm in algorithms.keys():\n",
    "        print(\"Running 5-fold cross validation with\", algorithm, \"on\", dataset, \"dataset ...\")\n",
    "        \n",
    "        # Run cross validation\n",
    "        best_prec_5 = 0\n",
    "        best_prec_10 = 0\n",
    "        best_rec_5 = 0\n",
    "        best_rec_10 = 0\n",
    "        fold_nr = 0\n",
    "        \n",
    "        for trainset, testset in kf.split(movielens_dataset):\n",
    "            print(\"Fold  number\", fold_nr)\n",
    "            algorithms[algorithm].fit(trainset)\n",
    "            predictions = algorithms[algorithm].test(testset)\n",
    "            predictions_df = pd.DataFrame(predictions)\n",
    "            predictions_df = predictions_df.iloc[:,:-1]\n",
    "            items_not_in_trainset = find_items_not_in_trainset(trainset, testset)\n",
    "            pres_at_5, recalls_at_5 = precision_recall_at_k(predictions_df, items_not_in_trainset, k=5)\n",
    "            pres_at_10, recalls_at_10 = precision_recall_at_k(predictions_df, items_not_in_trainset, k=10)\n",
    "            ndcgs = ndcg_for_rec(predictions_df)\n",
    "            avg_pre_5 = np.array([pres_at_5[k] for k in pres_at_5.keys()]).mean()\n",
    "            avg_rec_5 = np.array([recalls_at_5[k] for k in recalls_at_5.keys()]).mean()\n",
    "            avg_pre_10 = np.array([pres_at_10[k] for k in pres_at_10.keys()]).mean()\n",
    "            avg_rec_10 = np.array([recalls_at_10[k] for k in recalls_at_10.keys()]).mean()\n",
    "            avg_ndcg = np.array([ndcgs[k] for k in ndcgs.keys()]).mean()\n",
    "            if (avg_pre_5 > best_prec_5):\n",
    "                best_prec_5 = avg_pre_5\n",
    "            if (avg_pre_10 > best_prec_10):\n",
    "                best_prec_10 = avg_pre_10\n",
    "            if (avg_rec_5 > best_rec_5):\n",
    "                best_rec_5 = avg_rec_5\n",
    "            if (avg_rec_10 > best_rec_10):\n",
    "                best_rec_10 = avg_rec_10\n",
    "            fold_nr += 1\n",
    "            break\n",
    "        \n",
    "        new_line = [dataset+\"-\"+algorithm, best_prec_5, best_prec_10, best_rec_5, best_rec_10, avg_ndcg]\n",
    "        results_table.append(new_line)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Recommender     |    Pre@5 |   Pre@10 |    Rec@5 |   Rec@10 |     NDCG |\n",
      "|:----------------|---------:|---------:|---------:|---------:|---------:|\n",
      "| ML100-UserKNN   | 0.353387 | 0.360161 | 0.320818 | 0.477432 | 0.719624 |\n",
      "| ML100-ItemKNN   | 0.345903 | 0.348597 | 0.306494 | 0.452833 | 0.733329 |\n",
      "| PDA2018-UserKNN | 0.345392 | 0.358295 | 0.302015 | 0.459918 | 0.729926 |\n",
      "| PDA2018-ItemKNN | 0.352242 | 0.354596 | 0.315589 | 0.458352 | 0.732392 |\n"
     ]
    }
   ],
   "source": [
    "# Display results of running the algorithms\n",
    "results_table_headers = [\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Cornac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementations of MostPop, BPR and NCF are done by using the Cornac package, which is similiar to Surprise, but contains much more algorithms and metrics. \n",
    "- MostPop is a non-personalized model where the most popular/rated items are recommended to everyone.\n",
    "\n",
    "- NCF (Neural Collaborative Filtering) is a generalization of the matrix factorization problem using a multilayer perceptron.\n",
    "\n",
    "- BPR (Bayesian Personalised Ranking) is esentially a Matrix Factorization algorithm which is optimized with a Bayes Criterion (BPR-OPT) in order to make the recommendation list ranking as personalized to the user (hence as \"correct\") as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cornac\n",
    "from cornac.eval_methods import CrossValidation, RatioSplit\n",
    "from cornac.data import Reader\n",
    "from cornac.data import Dataset\n",
    "from cornac.hyperopt import Discrete, GridSearch\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and load the data using Cornac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens\n",
      "[('196', '242', 3.0), ('186', '302', 3.0), ('22', '377', 1.0), ('244', '51', 2.0), ('166', '346', 1.0)]\n",
      "\n",
      "PDA\n",
      "[('5', '648', 5.0), ('5', '1394', 5.0), ('5', '3534', 5.0), ('5', '104', 4.0), ('5', '2735', 5.0)]\n"
     ]
    }
   ],
   "source": [
    "# Init cornac reader object\n",
    "reader = Reader() # this binarises the data (turns it into implicit feedback)\n",
    "\n",
    "# Read both the datasets from the files using cornac\n",
    "movielens_data = reader.read(fpath=\"../data/u.data\", sep=\"\\t\")\n",
    "pda_data = reader.read(fpath=\"../data/train-PDA2018.csv\", sep=\",\", skip_lines=1)\n",
    "print(\"Movielens\")\n",
    "print(movielens_data[:5])\n",
    "print()\n",
    "print(\"PDA\")\n",
    "print(pda_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Popular model\n",
    "most_pop_model = cornac.models.MostPop()\n",
    "\n",
    "# NCF model: We'll use the Pre-Trained NeuMF model, since it performs better as shown in https://arxiv.org/pdf/1708.05031.pdf\n",
    "gmf = cornac.models.GMF(\n",
    "    num_factors=8,\n",
    "    num_epochs=10,\n",
    "    learner=\"adam\",\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    ")\n",
    "mlp = cornac.models.MLP(\n",
    "    layers=[64, 32, 16, 8],\n",
    "    act_fn=\"tanh\",\n",
    "    learner=\"adam\",\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    ")\n",
    "ncf_model = cornac.models.NeuMF(\n",
    "    name=\"NeuMF_pretrained\",\n",
    "    learner=\"adam\",\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    "    num_factors=gmf.num_factors,\n",
    "    layers=mlp.layers,\n",
    "    act_fn=mlp.act_fn,\n",
    ").pretrain(gmf, mlp)\n",
    "\n",
    "# BPR Model\n",
    "bpr_model = cornac.models.BPR(\n",
    "    k=10,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.01\n",
    ")\n",
    "\n",
    "# Eval Metrics\n",
    "pre_5 = cornac.metrics.Precision(k=5)\n",
    "pre_10 = cornac.metrics.Precision(k=10)\n",
    "rec_5 = cornac.metrics.Recall(k=5)\n",
    "rec_10 = cornac.metrics.Recall(k=10)\n",
    "ndcg = cornac.metrics.NDCG()\n",
    "auc = cornac.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EXPERIMENT VARIABLES\"\"\"\n",
    "# List that will contain the RMSE and MAE results\n",
    "cv_n_folds = 5 # define number of k splits for cross validation\n",
    "rating_threshold = 3 # This parameter is the threshold used for ranking metrics\n",
    "\n",
    "# Algorithms we will be using in this section\n",
    "cornac_algorithms = {\n",
    "    \"MostPop\": most_pop_model,\n",
    "    \"BPR\": bpr_model, \n",
    "    #\"NCF\": ncf_model\n",
    "}\n",
    "# Datasets\n",
    "datasets = {\n",
    "    \"ML100\": movielens_data,\n",
    "    \"PDA2018\": pda_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with MostPop on ML100 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1648\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1648\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924859bcb8364db3ad60c0e209363b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1652\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1652\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2b6f1e4a814c7aaaf8546681813720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1651\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1651\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fefe011c0444759affea3f4ccb463e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=940.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1656\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1656\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e09787100041d088ac8e1b3c94f1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1646\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1646\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b2c9ec5f4c4bfebefc40674fe9347c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[MostPop]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.8624 |  0.4056 |       0.0886 |      0.0946 |    0.0799 |   0.0431 |    0.0179 |   1.7061\n",
      "Fold 1 | 0.8660 |  0.4058 |       0.0888 |      0.0939 |    0.0785 |   0.0426 |    0.0064 |   1.6987\n",
      "Fold 2 | 0.8622 |  0.4000 |       0.0887 |      0.0898 |    0.0848 |   0.0397 |    0.0134 |   1.9315\n",
      "Fold 3 | 0.8630 |  0.4054 |       0.0905 |      0.1020 |    0.0867 |   0.0472 |    0.0068 |   1.6173\n",
      "Fold 4 | 0.8617 |  0.4050 |       0.0930 |      0.1036 |    0.0873 |   0.0466 |    0.0086 |   1.5265\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.8631 |  0.4044 |       0.0899 |      0.0968 |    0.0834 |   0.0438 |    0.0106 |   1.6960\n",
      "Std    | 0.0015 |  0.0022 |       0.0017 |      0.0052 |    0.0036 |   0.0028 |    0.0044 |   0.1345\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n",
      "Running 5-fold cross validation with BPR on ML100 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1648\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1648\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71c0b88bdeb419ebe3a511bd6774652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1652\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1652\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1120450c8d4d4905bd9e7c461941265e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1651\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1651\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881b2579cfaf43d8ad09398599cf849d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=940.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1656\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1656\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ad6cdb178e4e2e9a1e12fd58abc717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1646\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1646\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f5134d3a2b445c86ebf066f9aac7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[BPR]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.9345 |  0.4601 |       0.1138 |      0.1205 |    0.1199 |   0.0675 |    1.1255 |   1.7865\n",
      "Fold 1 | 0.9339 |  0.4581 |       0.1191 |      0.1288 |    0.1210 |   0.0678 |    1.1577 |   1.9061\n",
      "Fold 2 | 0.9320 |  0.4487 |       0.1146 |      0.1136 |    0.1183 |   0.0567 |    1.0978 |   1.6019\n",
      "Fold 3 | 0.9334 |  0.4516 |       0.1153 |      0.1222 |    0.1105 |   0.0613 |    1.1271 |   1.6049\n",
      "Fold 4 | 0.9319 |  0.4537 |       0.1124 |      0.1219 |    0.1115 |   0.0643 |    1.0878 |   1.9049\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.9332 |  0.4545 |       0.1151 |      0.1214 |    0.1162 |   0.0635 |    1.1192 |   1.7608\n",
      "Std    | 0.0010 |  0.0042 |       0.0022 |      0.0048 |    0.0044 |   0.0042 |    0.0246 |   0.1357\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n",
      "Running 5-fold cross validation with MostPop on PDA2018 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5679\n",
      "Number of items = 1823\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "---\n",
      "Total users = 5679\n",
      "Total items = 1823\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd437bc717de4248ada376ea477c3e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5313.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5685\n",
      "Number of items = 1821\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "---\n",
      "Total users = 5685\n",
      "Total items = 1821\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795ee9937cbe42d99095da4b9195209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5294.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1823\n",
      "Number of ratings = 376568\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1823\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20da230c8934652b73f7ef44569d0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5328.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1822\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1822\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0b95be485e4f0f857fb319b8bcfcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5303.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5682\n",
      "Number of items = 1820\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "---\n",
      "Total users = 5682\n",
      "Total items = 1820\n",
      "\n",
      "[MostPop] Training started!\n",
      "\n",
      "[MostPop] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36000c102944a69ba3eb66ee43dc39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5281.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[MostPop]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.8300 |  0.3487 |       0.0701 |      0.0739 |    0.0698 |   0.0394 |    0.0106 |   9.7591\n",
      "Fold 1 | 0.8296 |  0.3510 |       0.0710 |      0.0739 |    0.0701 |   0.0379 |    0.0105 |   9.1389\n",
      "Fold 2 | 0.8275 |  0.3482 |       0.0678 |      0.0724 |    0.0687 |   0.0376 |    0.0100 |   9.6338\n",
      "Fold 3 | 0.8256 |  0.3468 |       0.0684 |      0.0728 |    0.0660 |   0.0369 |    0.0101 |   8.1889\n",
      "Fold 4 | 0.8250 |  0.3490 |       0.0697 |      0.0764 |    0.0666 |   0.0392 |    0.0113 |   8.6919\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.8276 |  0.3487 |       0.0694 |      0.0739 |    0.0682 |   0.0382 |    0.0105 |   9.0825\n",
      "Std    | 0.0020 |  0.0014 |       0.0012 |      0.0014 |    0.0017 |   0.0010 |    0.0004 |   0.5858\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n",
      "Running 5-fold cross validation with BPR on PDA2018 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5679\n",
      "Number of items = 1823\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "---\n",
      "Total users = 5679\n",
      "Total items = 1823\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916acd1b0d4541b5983b9e32a35d4e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5313.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5685\n",
      "Number of items = 1821\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "---\n",
      "Total users = 5685\n",
      "Total items = 1821\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bfc26b3154496ba0aedcb8465e742b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5294.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1823\n",
      "Number of ratings = 376568\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1823\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae213a029e1c412cbb79b47113898b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5328.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1822\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1822\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4989f6a99347fda99daa30f6745c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5303.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5682\n",
      "Number of items = 1820\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "---\n",
      "Total users = 5682\n",
      "Total items = 1820\n",
      "\n",
      "[BPR] Training started!\n",
      "\n",
      "[BPR] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6639707271454378a45d7965f3d001c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5281.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[BPR]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.9036 |  0.3902 |       0.0906 |      0.0955 |    0.1014 |   0.0547 |    6.3063 |   8.5180\n",
      "Fold 1 | 0.9032 |  0.3918 |       0.0907 |      0.0953 |    0.1009 |   0.0544 |    5.6859 |   8.2109\n",
      "Fold 2 | 0.9025 |  0.3891 |       0.0885 |      0.0947 |    0.0935 |   0.0522 |    5.5935 |   9.9494\n",
      "Fold 3 | 0.9001 |  0.3891 |       0.0890 |      0.0958 |    0.0961 |   0.0545 |    7.4534 |  11.9435\n",
      "Fold 4 | 0.9003 |  0.3881 |       0.0891 |      0.0940 |    0.0948 |   0.0519 |    7.7802 |   9.5763\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.9020 |  0.3897 |       0.0896 |      0.0950 |    0.0973 |   0.0536 |    6.5639 |   9.6396\n",
      "Std    | 0.0014 |  0.0013 |       0.0009 |      0.0006 |    0.0032 |   0.0012 |    0.8999 |   1.3196\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for algorithm in cornac_algorithms.keys():\n",
    "        print(\"Running 5-fold cross validation with\", algorithm, \"on\", dataset, \"dataset ...\\n\\n\")\n",
    "        # Define Cornac cross validation object\n",
    "        cv = CrossValidation(\n",
    "            data=datasets[dataset],\n",
    "            n_folds=cv_n_folds,\n",
    "            rating_threshold=rating_threshold, # This parameter is the threshold used for ranking metrics\n",
    "            seed = 0,\n",
    "            verbose=True\n",
    "        )\n",
    "        # Define Cornac experiment (put everything together)\n",
    "        experiment = cornac.Experiment(\n",
    "            eval_method=cv,\n",
    "            models=[cornac_algorithms[algorithm]],    \n",
    "            metrics=[pre_5, pre_10, rec_5, rec_10, auc, ndcg],\n",
    "        )\n",
    "        experiment.run()\n",
    "        for entry in experiment.result:\n",
    "            results_dict = entry[0].metric_avg_results\n",
    "            print(results_dict.keys())\n",
    "            new_line = [dataset+\"-\"+algorithm, results_dict['Precision@5'], results_dict['Precision@10'], \\\n",
    "                        results_dict['Recall@5'], results_dict['Recall@10'], results_dict['NDCG@-1']]\n",
    "            results_table.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Recommender     |     Pre@5 |    Pre@10 |     Rec@5 |    Rec@10 |     NDCG |\n",
      "|:----------------|----------:|----------:|----------:|----------:|---------:|\n",
      "| ML100-UserKNN   | 0.353387  | 0.360161  | 0.320818  | 0.477432  | 0.719624 |\n",
      "| ML100-ItemKNN   | 0.345903  | 0.348597  | 0.306494  | 0.452833  | 0.733329 |\n",
      "| PDA2018-UserKNN | 0.345392  | 0.358295  | 0.302015  | 0.459918  | 0.729926 |\n",
      "| PDA2018-ItemKNN | 0.352242  | 0.354596  | 0.315589  | 0.458352  | 0.732392 |\n",
      "| ML100-MostPop   | 0.0945802 | 0.0886291 | 0.0431486 | 0.0799196 | 0.405632 |\n",
      "| ML100-BPR       | 0.12051   | 0.113815  | 0.067483  | 0.119924  | 0.460105 |\n",
      "| PDA2018-MostPop | 0.0739311 | 0.0701476 | 0.0394338 | 0.0697588 | 0.348685 |\n",
      "| PDA2018-BPR     | 0.0954975 | 0.09056   | 0.0547475 | 0.101405  | 0.390186 |\n"
     ]
    }
   ],
   "source": [
    "# Display results of running the algorithms\n",
    "results_table_headers = [\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "# Export the results to a csv file\n",
    "results_df = pd.DataFrame(results_table, columns=[\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"])\n",
    "results_df.to_csv(\"../data/items_recommendation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
