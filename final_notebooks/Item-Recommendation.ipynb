{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import KFold, cross_validate\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and load the data using Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML100K\n",
      "    userID  itemID  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "\n",
      "\n",
      "\n",
      "PDA2018\n",
      "    userID  itemID  rating  timeStamp\n",
      "0       5     648       5  978297876\n",
      "1       5    1394       5  978298237\n",
      "2       5    3534       5  978297149\n",
      "3       5     104       4  978298558\n",
      "4       5    2735       5  978297919\n",
      "Shapes before sub-sampling:\n",
      "(100000, 4)\n",
      "(470711, 4)\n",
      "\n",
      "Shapes after sub-sampling:\n",
      "(97623, 4)\n",
      "(465154, 4)\n",
      "\n",
      " Some general information on the training sets we will be using:\n",
      "1) Number of items in each dataset  ML100k: 1682 PDA: 1824\n",
      "2) Number of users in each dataset  ML100k: 943 PDA: 5690\n",
      "3) Number of ratings in each dataset  ML100k: 100000 PDA: 470711\n",
      "4) Mean rating  ML100k: 3.52986 PDA: 3.638361967321775\n"
     ]
    }
   ],
   "source": [
    "# Read both the datasets from the files using pandas\n",
    "movielens_df = pd.read_csv(\"../data/u.data\", sep=\"\\t\", header=None)\n",
    "movielens_df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    "pda_df = pd.read_csv(\"../data/train-PDA2018.csv\", sep=\",\")\n",
    "print(\"ML100K\\n\", movielens_df.head())\n",
    "print(\"\\n\\n\")\n",
    "print(\"PDA2018\\n\", pda_df.head())\n",
    "\n",
    "# Sample the data such that every user has rated at least 10 items and every item has been by at least 10 users\n",
    "print(\"Shapes before sub-sampling:\")\n",
    "print(movielens_df.shape)\n",
    "print(pda_df.shape)\n",
    "\n",
    "# Movielens users all have at least 20 ratings so no need to subsample the user values\n",
    "ml_subsampled = movielens_df[movielens_df['itemID'].isin(movielens_df['itemID'].value_counts()[movielens_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_df[pda_df['itemID'].isin(pda_df['itemID'].value_counts()[pda_df['itemID'].value_counts()>10].index)]\n",
    "pda_subsampled = pda_subsampled[pda_subsampled['userID'].isin(pda_subsampled['userID'].value_counts()[pda_subsampled['userID'].value_counts()>10].index)]\n",
    "print(\"\\nShapes after sub-sampling:\")\n",
    "print(ml_subsampled.shape)\n",
    "print(pda_subsampled.shape)\n",
    "\n",
    "# Create the training datasets using Surprise's reader class\n",
    "reader = Reader(rating_scale=(1,5)) # We have ratings from 1 to 5 so we create the rating scale\n",
    "\n",
    "# Load the data from the dataframes\n",
    "movielens_dataset = Dataset.load_from_df(movielens_df.iloc[:,0:3], reader)\n",
    "pda_dataset = Dataset.load_from_df(pda_df.iloc[:,0:3], reader)\n",
    "\n",
    "# Build full trainsets to print out the data loaded above\n",
    "mls_train = movielens_dataset.build_full_trainset()\n",
    "pda_train = pda_dataset.build_full_trainset()\n",
    "\n",
    "# Print out some basic information about the datasets\n",
    "print(\"\\n Some general information on the training sets we will be using:\")\n",
    "print(\"1) Number of items in each dataset\", \" ML100k:\", mls_train.n_items, \"PDA:\", pda_train.n_items)\n",
    "print(\"2) Number of users in each dataset\", \" ML100k:\", mls_train.n_users, \"PDA:\", pda_train.n_users)\n",
    "print(\"3) Number of ratings in each dataset\", \" ML100k:\", mls_train.n_ratings, \"PDA:\", pda_train.n_ratings)\n",
    "print(\"4) Mean rating\", \" ML100k:\", mls_train.global_mean, \"PDA:\", pda_train.global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise experiment parameters and variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Define auxilliary functions to get Top-N and then calculate precision and recall in Surprise + more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have ratings in the train set for all the users in the test set\n",
    "def find_items_not_in_trainset(trainset, testset):\n",
    "    items_not_in_train = []\n",
    "    for _,itemId, _ in testset:    \n",
    "        if itemId not in trainset.ir.keys():\n",
    "            items_not_in_train.append(itemId)\n",
    "            \n",
    "    return items_not_in_train\n",
    "\n",
    "        \n",
    "def user_seen_items(userId):\n",
    "    return [train_itemId for train_itemId, rating in mls_train.ur[userId]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n, minimumRating, criterion):\n",
    "    topN = defaultdict(list)\n",
    "    \n",
    "    for index, row in predictions.iterrows():\n",
    "        if (row[criterion] >= minimumRating):\n",
    "            topN[int(row.uid)].append((int(row.iid), row[criterion]))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, items_not_in_train, k, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions, n=k, minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions, n=k, minimumRating=threshold, criterion=\"r_ui\")\n",
    "    above_threshold = predictions[predictions.r_ui >= threshold]\n",
    "\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "\n",
    "    for uid, est_topn in top_n_recoms_est.items():\n",
    "        # Get items the user has already rated\n",
    "        already_seen = user_seen_items(uid)\n",
    "        # Get relevant items for the user\n",
    "        n_rel_for_user = len(above_threshold[above_threshold.uid == uid])        \n",
    "        tp = 0\n",
    "        # Penalize the scores if:\n",
    "        # - The item we are recommending was never seen in the training set (how could we recommend what we don't know?)\n",
    "        # - The user has already rated this item: It's not a good recommendation since the user already knows it/has seen it\n",
    "        for est_itemId, _ in est_topn:\n",
    "            if(est_itemId in items_not_in_train or est_itemId in already_seen):\n",
    "                tp += 0\n",
    "            else:\n",
    "                for real_itemId, _ in top_n_recoms_real[uid]:\n",
    "                    if (est_itemId == real_itemId):\n",
    "                        tp +=1\n",
    "        \n",
    "        precisions[uid] = tp/k\n",
    "        recalls[uid] = tp/n_rel_for_user if n_rel_for_user != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "def ndcg_for_rec(predictions, threshold=3.5):\n",
    "    top_n_recoms_est = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"est\")\n",
    "    top_n_recoms_real = GetTopN(predictions, n=predictions.shape[0], minimumRating=threshold, criterion=\"r_ui\")\n",
    "    ndcgs = {}\n",
    "\n",
    "    for uid, real_topn in top_n_recoms_real.items():\n",
    "        user_gt = [true_rating[0] for true_rating in real_topn]\n",
    "        est_top_for_current = top_n_recoms_est[uid]\n",
    "        predicted_items = [est_rating[0] for est_rating in est_top_for_current]\n",
    "        predicted_scores = [est_rating[1] for est_rating in est_top_for_current]\n",
    "        gain_scores = np.zeros(len(user_gt)).tolist()\n",
    "\n",
    "        ndcg_val = 0\n",
    "        \n",
    "        if(len(predicted_items) == 0):\n",
    "            ndcg_val += 0\n",
    "        elif(len(predicted_items) == 1 or len(user_gt) == 1):\n",
    "            if(predicted_items[0] == user_gt[0]):\n",
    "                ndcg_val += 1\n",
    "        else:\n",
    "            for i, pred_item in enumerate(predicted_items):\n",
    "                for j, gt_item in enumerate(user_gt):\n",
    "                    if(gt_item==pred_item):\n",
    "                        gain_scores[j] = i\n",
    "            gain_scores =[int(elem) for elem in gain_scores]\n",
    "            ndcg_val += ndcg_score(np.asarray([user_gt]), np.asarray([gain_scores]))\n",
    "            \n",
    "        #print(\"GT:\", user_gt)\n",
    "        #print(\"Pred:\", predicted_items)\n",
    "        #print(gain_scores)\n",
    "        #print( \"\\n\\n\")\n",
    "        ndcgs[uid] = ndcg_val\n",
    "\n",
    "    return ndcgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EXPERIMENT VARIABLES\"\"\"\n",
    "# List that will contain the results of all experiments\n",
    "results_table = []\n",
    "kf = KFold(n_splits=5) # define number of k splits for cross validation using Surprise KFold\n",
    "\n",
    "# Algorithms we will be using in this section\n",
    "algorithms = {\n",
    "    \"UserKNN\": KNNWithMeans(k=60, sim_options={'name': 'pearson_baseline', 'shrinkage': 25, 'user_based': True}),\n",
    "    \"ItemKNN\": KNNWithMeans(k=40, sim_options={'name': 'pearson_baseline', 'shrinkage': 25, 'user_based': False}),\n",
    "}\n",
    "# Datasets\n",
    "datasets = {\n",
    "    \"ML100\": movielens_dataset,\n",
    "    \"PDA2018\": pda_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with UserKNN on ML100 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with ItemKNN on ML100 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with UserKNN on PDA2018 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Running 5-fold cross validation with ItemKNN on PDA2018 dataset ...\n",
      "Fold  number 0\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for algorithm in algorithms.keys():\n",
    "        print(\"Running 5-fold cross validation with\", algorithm, \"on\", dataset, \"dataset ...\")\n",
    "        \n",
    "        # Run cross validation\n",
    "        best_prec_5 = 0\n",
    "        best_prec_10 = 0\n",
    "        best_rec_5 = 0\n",
    "        best_rec_10 = 0\n",
    "        fold_nr = 0\n",
    "        \n",
    "        for trainset, testset in kf.split(movielens_dataset):\n",
    "            print(\"Fold  number\", fold_nr)\n",
    "            algorithms[algorithm].fit(trainset)\n",
    "            predictions = algorithms[algorithm].test(testset)\n",
    "            predictions_df = pd.DataFrame(predictions)\n",
    "            predictions_df = predictions_df.iloc[:,:-1]\n",
    "            items_not_in_trainset = find_items_not_in_trainset(trainset, testset)\n",
    "            pres_at_5, recalls_at_5 = precision_recall_at_k(predictions_df, items_not_in_trainset, k=5)\n",
    "            pres_at_10, recalls_at_10 = precision_recall_at_k(predictions_df, items_not_in_trainset, k=10)\n",
    "            ndcgs = ndcg_for_rec(predictions_df)\n",
    "            avg_pre_5 = np.array([pres_at_5[k] for k in pres_at_5.keys()]).mean()\n",
    "            avg_rec_5 = np.array([recalls_at_5[k] for k in recalls_at_5.keys()]).mean()\n",
    "            avg_pre_10 = np.array([pres_at_10[k] for k in pres_at_10.keys()]).mean()\n",
    "            avg_rec_10 = np.array([recalls_at_10[k] for k in recalls_at_10.keys()]).mean()\n",
    "            avg_ndcg = np.array([ndcgs[k] for k in ndcgs.keys()]).mean()\n",
    "            if (avg_pre_5 > best_prec_5):\n",
    "                best_prec_5 = avg_pre_5\n",
    "            if (avg_pre_10 > best_prec_10):\n",
    "                best_prec_10 = avg_pre_10\n",
    "            if (avg_rec_5 > best_rec_5):\n",
    "                best_rec_5 = avg_rec_5\n",
    "            if (avg_rec_10 > best_rec_10):\n",
    "                best_rec_10 = avg_rec_10\n",
    "            fold_nr += 1\n",
    "            break\n",
    "        \n",
    "        new_line = [dataset+\"-\"+algorithm, best_prec_5, best_prec_10, best_rec_5, best_rec_10, avg_ndcg]\n",
    "        results_table.append(new_line)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Recommender     |    Pre@5 |   Pre@10 |    Rec@5 |   Rec@10 |     NDCG |\n",
      "|:----------------|---------:|---------:|---------:|---------:|---------:|\n",
      "| ML100-UserKNN   | 0.353387 | 0.360161 | 0.320818 | 0.477432 | 0.719624 |\n",
      "| ML100-ItemKNN   | 0.345903 | 0.348597 | 0.306494 | 0.452833 | 0.733329 |\n",
      "| PDA2018-UserKNN | 0.345392 | 0.358295 | 0.302015 | 0.459918 | 0.729926 |\n",
      "| PDA2018-ItemKNN | 0.352242 | 0.354596 | 0.315589 | 0.458352 | 0.732392 |\n"
     ]
    }
   ],
   "source": [
    "# Display results of running the algorithms\n",
    "results_table_headers = [\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Cornac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementations of MostPop, BPR and NCF are done by using the Cornac package, which is similiar to Surprise, but contains much more algorithms and metrics. \n",
    "- MostPop is a non-personalized model where the most popular/rated items are recommended to everyone.\n",
    "\n",
    "- NCF (Neural Collaborative Filtering) is a generalization of the matrix factorization problem using a multilayer perceptron.\n",
    "\n",
    "- BPR (Bayesian Personalised Ranking) is esentially a Matrix Factorization algorithm which is optimized with a Bayes Criterion (BPR-OPT) in order to make the recommendation list ranking as personalized to the user (hence as \"correct\") as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cornac\n",
    "from cornac.eval_methods import CrossValidation, RatioSplit\n",
    "from cornac.data import Reader\n",
    "from cornac.data import Dataset\n",
    "from cornac.hyperopt import Discrete, GridSearch\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and load the data using Cornac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens\n",
      "[('196', '242', 3.0), ('186', '302', 3.0), ('22', '377', 1.0), ('244', '51', 2.0), ('166', '346', 1.0)]\n",
      "\n",
      "PDA\n",
      "[('5', '648', 5.0), ('5', '1394', 5.0), ('5', '3534', 5.0), ('5', '104', 4.0), ('5', '2735', 5.0)]\n"
     ]
    }
   ],
   "source": [
    "# Init cornac reader object\n",
    "reader = Reader() # this binarises the data (turns it into implicit feedback)\n",
    "\n",
    "# Read both the datasets from the files using cornac\n",
    "movielens_data = reader.read(fpath=\"../data/u.data\", sep=\"\\t\")\n",
    "pda_data = reader.read(fpath=\"../data/train-PDA2018.csv\", sep=\",\", skip_lines=1)\n",
    "print(\"Movielens\")\n",
    "print(movielens_data[:5])\n",
    "print()\n",
    "print(\"PDA\")\n",
    "print(pda_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Popular model\n",
    "most_pop_model = cornac.models.MostPop()\n",
    "\n",
    "# NCF model: We'll use the Pre-Trained NeuMF model, since it performs better as shown in https://arxiv.org/pdf/1708.05031.pdf\n",
    "gmf = cornac.models.GMF(\n",
    "    num_factors=8,\n",
    "    num_epochs=10,\n",
    "    learner=\"adam\",\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    ")\n",
    "mlp = cornac.models.MLP(\n",
    "    layers=[64, 32, 16, 8],\n",
    "    act_fn=\"tanh\",\n",
    "    learner=\"adam\",\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    ")\n",
    "ncf_model = cornac.models.NeuMF(\n",
    "    name=\"NeuMF_pretrained\",\n",
    "    learner=\"adam\",\n",
    "    num_epochs=5,\n",
    "    batch_size=256,\n",
    "    lr=0.001,\n",
    "    num_neg=50,\n",
    "    seed=123,\n",
    "    num_factors=gmf.num_factors,\n",
    "    layers=mlp.layers,\n",
    "    act_fn=mlp.act_fn,\n",
    ").pretrain(gmf, mlp)\n",
    "\n",
    "# BPR Model\n",
    "bpr_model = cornac.models.BPR(\n",
    "    k=10,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.01\n",
    ")\n",
    "\n",
    "# Eval Metrics\n",
    "pre_5 = cornac.metrics.Precision(k=5)\n",
    "pre_10 = cornac.metrics.Precision(k=10)\n",
    "rec_5 = cornac.metrics.Recall(k=5)\n",
    "rec_10 = cornac.metrics.Recall(k=10)\n",
    "ndcg = cornac.metrics.NDCG()\n",
    "auc = cornac.metrics.AUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" EXPERIMENT VARIABLES\"\"\"\n",
    "# List that will contain the RMSE and MAE results\n",
    "cv_n_folds = 5 # define number of k splits for cross validation\n",
    "rating_threshold = 3 # This parameter is the threshold used for ranking metrics\n",
    "\n",
    "# Algorithms we will be using in this section\n",
    "cornac_algorithms = {\n",
    "    #\"MostPop\": most_pop_model,\n",
    "    #\"BPR\": bpr_model, \n",
    "    \"NCF\": ncf_model\n",
    "}\n",
    "# Datasets\n",
    "datasets = {\n",
    "    \"ML100\": movielens_data,\n",
    "    \"PDA2018\": pda_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with NCF on ML100 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1648\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1382\n",
      "Number of ratings = 19966\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1648\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d59b5ee58554647b073799c8dd58844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4df0a2ed014680b49c4b3f2701ba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1652\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1371\n",
      "Number of ratings = 19967\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1652\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2a5c9c1dc141288d2d90d3ab800a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d192f623714f2aafaa3dc558a0c949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1651\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 940\n",
      "Number of items = 1390\n",
      "Number of ratings = 19965\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1651\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5012ed05c9dc46c7b9aae8290602692c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034e5111da3e4370b3cc38796dfd0d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=940.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1656\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 943\n",
      "Number of items = 1397\n",
      "Number of ratings = 19969\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1656\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198aef75019246ba9fa05ee870308b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713c8a97b32e42ac8c4a95cdfc45577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=943.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 943\n",
      "Number of items = 1646\n",
      "Number of ratings = 80000\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.5\n",
      "---\n",
      "Test data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 942\n",
      "Number of items = 1383\n",
      "Number of ratings = 19959\n",
      "---\n",
      "Total users = 943\n",
      "Total items = 1646\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f42c4e14cf42058c5836bcc50fe8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f725b685347c49519c7663f44d984f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=942.0, style=ProgressStyle(description_widtâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[NeuMF_pretrained]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.8834 |  0.4291 |       0.1039 |      0.1063 |    0.0997 |   0.0532 |  608.6646 |   2.7172\n",
      "Fold 1 | 0.8873 |  0.4324 |       0.1103 |      0.1197 |    0.1060 |   0.0634 |  582.5867 |   2.3999\n",
      "Fold 2 | 0.8840 |  0.4254 |       0.1036 |      0.1134 |    0.1033 |   0.0586 |  572.2780 |   2.3785\n",
      "Fold 3 | 0.8859 |  0.4312 |       0.1123 |      0.1256 |    0.1029 |   0.0619 |  567.4948 |   2.3629\n",
      "Fold 4 | 0.8838 |  0.4287 |       0.1100 |      0.1140 |    0.1052 |   0.0560 |  567.6391 |   2.3342\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.8849 |  0.4294 |       0.1080 |      0.1158 |    0.1034 |   0.0586 |  579.7326 |   2.4385\n",
      "Std    | 0.0015 |  0.0024 |       0.0036 |      0.0065 |    0.0022 |   0.0037 |   15.4712 |   0.1410\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n",
      "Running 5-fold cross validation with NCF on PDA2018 dataset ...\n",
      "\n",
      "\n",
      "rating_threshold = 3.0\n",
      "exclude_unknowns = True\n",
      "Fold: 1\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5679\n",
      "Number of items = 1823\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5313\n",
      "Number of items = 1780\n",
      "Number of ratings = 94116\n",
      "---\n",
      "Total users = 5679\n",
      "Total items = 1823\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4b208b530e47a69cd4e33350b846bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bd5f056d2047168b6cdfb990bbfc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5313.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 2\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5685\n",
      "Number of items = 1821\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5294\n",
      "Number of items = 1791\n",
      "Number of ratings = 94127\n",
      "---\n",
      "Total users = 5685\n",
      "Total items = 1821\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897c91074dd84dc9835eed42df8f4738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b59a02c9ef4619b4fa2dc233c6f23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5294.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 3\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1823\n",
      "Number of ratings = 376568\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5328\n",
      "Number of items = 1798\n",
      "Number of ratings = 94129\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1823\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b300ed63ada14c3fb5255114475b397a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef61b541b3714a7793f5f0dd4d81eb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5328.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 4\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5684\n",
      "Number of items = 1822\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5303\n",
      "Number of items = 1787\n",
      "Number of ratings = 94125\n",
      "---\n",
      "Total users = 5684\n",
      "Total items = 1822\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10395ae744e0460ab87d454a9fa69849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdefa361c7d74d7b895431119ba60b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5303.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold: 5\n",
      "---\n",
      "Training data:\n",
      "Number of users = 5682\n",
      "Number of items = 1820\n",
      "Number of ratings = 376569\n",
      "Max rating = 5.0\n",
      "Min rating = 1.0\n",
      "Global mean = 3.6\n",
      "---\n",
      "Test data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "Number of unknown users = 0\n",
      "Number of unknown items = 0\n",
      "---\n",
      "Validation data:\n",
      "Number of users = 5281\n",
      "Number of items = 1799\n",
      "Number of ratings = 94121\n",
      "---\n",
      "Total users = 5682\n",
      "Total items = 1820\n",
      "\n",
      "[NeuMF_pretrained] Training started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dd2d204b574d6982ae37f3b8cd2a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[NeuMF_pretrained] Evaluation started!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71743788b554072895945c5c5a5db2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Ranking', max=5281.0, style=ProgressStyle(description_widâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST:\n",
      "...\n",
      "[NeuMF_pretrained]\n",
      "       |    AUC | NDCG@-1 | Precision@10 | Precision@5 | Recall@10 | Recall@5 | Train (s) | Test (s)\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Fold 0 | 0.8842 |  0.3791 |       0.0840 |      0.0897 |    0.0935 |   0.0512 | 2721.4121 |  13.4916\n",
      "Fold 1 | 0.8848 |  0.3793 |       0.0822 |      0.0870 |    0.0882 |   0.0489 | 2696.9129 |  13.2230\n",
      "Fold 2 | 0.8825 |  0.3772 |       0.0819 |      0.0845 |    0.0870 |   0.0482 | 2718.9898 |  13.1119\n",
      "Fold 3 | 0.8803 |  0.3755 |       0.0818 |      0.0854 |    0.0879 |   0.0470 | 2708.5357 |  13.1217\n",
      "Fold 4 | 0.8798 |  0.3765 |       0.0814 |      0.0876 |    0.0840 |   0.0484 | 2715.3192 |  13.0332\n",
      "------ + ------ + ------- + ------------ + ----------- + --------- + -------- + --------- + --------\n",
      "Mean   | 0.8823 |  0.3775 |       0.0822 |      0.0868 |    0.0881 |   0.0487 | 2712.2339 |  13.1963\n",
      "Std    | 0.0020 |  0.0015 |       0.0009 |      0.0018 |    0.0031 |   0.0014 |    8.8069 |   0.1595\n",
      "\n",
      "odict_keys(['AUC', 'NDCG@-1', 'Precision@10', 'Precision@5', 'Recall@10', 'Recall@5', 'Train (s)', 'Test (s)'])\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for algorithm in cornac_algorithms.keys():\n",
    "        print(\"Running 5-fold cross validation with\", algorithm, \"on\", dataset, \"dataset ...\\n\\n\")\n",
    "        # Define Cornac cross validation object\n",
    "        cv = CrossValidation(\n",
    "            data=datasets[dataset],\n",
    "            n_folds=cv_n_folds,\n",
    "            rating_threshold=rating_threshold, # This parameter is the threshold used for ranking metrics\n",
    "            seed = 0,\n",
    "            verbose=True\n",
    "        )\n",
    "        # Define Cornac experiment (put everything together)\n",
    "        experiment = cornac.Experiment(\n",
    "            eval_method=cv,\n",
    "            models=[cornac_algorithms[algorithm]],    \n",
    "            metrics=[pre_5, pre_10, rec_5, rec_10, auc, ndcg],\n",
    "        )\n",
    "        experiment.run()\n",
    "        for entry in experiment.result:\n",
    "            results_dict = entry[0].metric_avg_results\n",
    "            print(results_dict.keys())\n",
    "            new_line = [dataset+\"-\"+algorithm, results_dict['Precision@5'], results_dict['Precision@10'], \\\n",
    "                        results_dict['Recall@5'], results_dict['Recall@10'], results_dict['NDCG@-1']]\n",
    "            results_table.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Recommender     |     Pre@5 |    Pre@10 |     Rec@5 |    Rec@10 |     NDCG |\n",
      "|:----------------|----------:|----------:|----------:|----------:|---------:|\n",
      "| ML100-UserKNN   | 0.353387  | 0.360161  | 0.320818  | 0.477432  | 0.719624 |\n",
      "| ML100-ItemKNN   | 0.345903  | 0.348597  | 0.306494  | 0.452833  | 0.733329 |\n",
      "| PDA2018-UserKNN | 0.345392  | 0.358295  | 0.302015  | 0.459918  | 0.729926 |\n",
      "| PDA2018-ItemKNN | 0.352242  | 0.354596  | 0.315589  | 0.458352  | 0.732392 |\n",
      "| ML100-MostPop   | 0.0945802 | 0.0886291 | 0.0431486 | 0.0799196 | 0.405632 |\n",
      "| ML100-BPR       | 0.12051   | 0.113815  | 0.067483  | 0.119924  | 0.460105 |\n",
      "| PDA2018-MostPop | 0.0739311 | 0.0701476 | 0.0394338 | 0.0697588 | 0.348685 |\n",
      "| PDA2018-BPR     | 0.0954975 | 0.09056   | 0.0547475 | 0.101405  | 0.390186 |\n",
      "| ML100-NCF       | 0.10627   | 0.103932  | 0.0532409 | 0.0997437 | 0.429081 |\n",
      "| PDA2018-NCF     | 0.0897465 | 0.0839955 | 0.0511921 | 0.0935042 | 0.379135 |\n"
     ]
    }
   ],
   "source": [
    "# Display results of running the algorithms\n",
    "results_table_headers = [\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "# Export the results to a csv file\n",
    "results_df = pd.DataFrame(results_table, columns=[\"Recommender\", \"Pre@5\", \"Pre@10\", \"Rec@5\", \"Rec@10\", \"NDCG\"])\n",
    "results_df.to_csv(\"../data/items_recommendation_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
