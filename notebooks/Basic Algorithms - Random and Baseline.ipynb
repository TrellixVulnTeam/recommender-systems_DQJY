{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import BaselineOnly, NormalPredictor\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userID  itemID  rating  timestamp\n",
      "0     196     242       3  881250949\n",
      "1     186     302       3  891717742\n",
      "2      22     377       1  878887116\n",
      "3     244      51       2  880606923\n",
      "4     166     346       1  886397596\n",
      "\n",
      "\n",
      "\n",
      "   userID  itemID  rating  timeStamp\n",
      "0       5     648       5  978297876\n",
      "1       5    1394       5  978298237\n",
      "2       5    3534       5  978297149\n",
      "3       5     104       4  978298558\n",
      "4       5    2735       5  978297919\n"
     ]
    }
   ],
   "source": [
    "# Read both the datasets from the files using pandas\n",
    "movielens_df = pd.read_csv(\"../data/u.data\", sep=\"\\t\", header=None)\n",
    "movielens_df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
    "pda_df = pd.read_csv(\"../data/train-PDA2018.csv\", sep=\",\")\n",
    "print(movielens_df.head())\n",
    "print(\"\\n\\n\")\n",
    "print(pda_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information on the training sets we will be using \n",
      "\n",
      "1) Number of items in each dataset  ML100k: 1682 PDA: 1824\n",
      "2) Number of users in each dataset  ML100k: 943 PDA: 5690\n",
      "3) Number of ratings in each dataset  ML100k: 100000 PDA: 470711\n",
      "4) Mean rating  ML100k: 3.52986 PDA: 3.638361967321775\n"
     ]
    }
   ],
   "source": [
    "# Create the training datasets using Surprise's reader class\n",
    "reader = Reader(rating_scale=(1,5)) # We have ratings from 1 to 5 so we create the rating scale\n",
    "\n",
    "# Load the data from the dataframes\n",
    "movielens_dataset = Dataset.load_from_df(movielens_df.iloc[:,0:3], reader)\n",
    "pda_dataset = Dataset.load_from_df(pda_df.iloc[:,0:3], reader)\n",
    "\n",
    "# Build full trainsets to print out the data loaded above\n",
    "mls_train = movielens_dataset.build_full_trainset()\n",
    "pda_train = pda_dataset.build_full_trainset()\n",
    "\n",
    "# Print out some basic information about the datasets\n",
    "print(\"General information on the training sets we will be using \\n\")\n",
    "print(\"1) Number of items in each dataset\", \" ML100k:\", mls_train.n_items, \"PDA:\", pda_train.n_items)\n",
    "print(\"2) Number of users in each dataset\", \" ML100k:\", mls_train.n_users, \"PDA:\", pda_train.n_users)\n",
    "print(\"3) Number of ratings in each dataset\", \" ML100k:\", mls_train.n_ratings, \"PDA:\", pda_train.n_ratings)\n",
    "print(\"4) Mean rating\", \" ML100k:\", mls_train.global_mean, \"PDA:\", pda_train.global_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random (Normal) Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List that will contain the RMSE and MAE results\n",
    "results_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with Random Predictor on MovieLens-100K dataset ...\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5) # define number of k splits for cross validation\n",
    "print(\"Running 5-fold cross validation with Random Predictor on MovieLens-100K dataset ...\")\n",
    "out = cross_validate(NormalPredictor(), movielens_dataset, [\"rmse\", \"mae\"], kf)\n",
    "mean_rmse = \"{:.3f}.\".format(np.mean(out[\"test_rmse\"]))\n",
    "mean_mae = \"{:.3f}.\".format(np.mean(out[\"test_mae\"]))\n",
    "new_line = [\"ML100K-Random\", mean_rmse, mean_mae]\n",
    "results_table.append(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-fold cross validation with Random Predictor on PDA2018 dataset ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Running 5-fold cross validation with Random Predictor on PDA2018 dataset ...\")\n",
    "out = cross_validate(NormalPredictor(), pda_dataset, [\"rmse\", \"mae\"], kf)\n",
    "mean_rmse = \"{:.3f}.\".format(np.mean(out[\"test_rmse\"]))\n",
    "mean_mae = \"{:.3f}.\".format(np.mean(out[\"test_mae\"]))\n",
    "new_line = [\"PDA2018-Random\", mean_rmse, mean_mae]\n",
    "results_table.append(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (Mean + Biases) Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for the BaselineOnly algorithm ...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "\n",
      "Results:\n",
      "Best RMSE: 0.9405776667007226\n",
      "Best params for RMSE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "Best MAE: 0.7430169746642233\n",
      "Best params for MAE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For this algorithm we can run GridSearch CrossValidation, which will help us find the best parameters \n",
    "# and also the best RMSE and MAE values\n",
    "# Define the parameters and their respective ranges\n",
    "param_grid = {\n",
    "    \"bsl_options\": {\n",
    "        \"method\": [\"als\", \"sgd\"],\n",
    "        \"reg\": [0.01, 0.5], \n",
    "        \"n_epochs\": [5,20]\n",
    "    }\n",
    "}\n",
    "\n",
    "## RUN 1: MOVIELENS\n",
    "\n",
    "# Run grid search for the specified algorithm and the parameter grid\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=5) # 5-fold CV\n",
    "print(\"Running grid search for the BaselineOnly algorithm ...\")\n",
    "# Fit the moviesdata to the model using the parameters of the grid search\n",
    "gs.fit(movielens_dataset)\n",
    "# Save the best parameters of the models and the best scores\n",
    "results_table.append([\"ML100-Baseline\", '{:.3f}.'.format(gs.best_score[\"rmse\"]), '{:.3f}.'.format(gs.best_score[\"mae\"])])\n",
    "# Print out the the best RMSE, MAE and the respective model parameters\n",
    "print(\"\\nResults:\")\n",
    "print(\"Best RMSE:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params for RMSE\", gs.best_params[\"rmse\"])\n",
    "print(\"Best MAE:\", gs.best_score[\"mae\"])\n",
    "print(\"Best params for MAE\", gs.best_params[\"mae\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for the BaselineOnly algorithm ...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "Estimating biases using sgd...\n",
      "\n",
      "Results:\n",
      "Best RMSE: 0.9028829763550886\n",
      "Best params for RMSE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "Best MAE: 0.7112054587973544\n",
      "Best params for MAE {'bsl_options': {'method': 'sgd', 'reg': 0.01, 'n_epochs': 20}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RUN 2: PDA2018\n",
    "\n",
    "# Run grid search for the specified algorithm and the parameter grid\n",
    "gs = GridSearchCV(BaselineOnly, param_grid, measures=[\"rmse\", \"mae\"], cv=5) # 5-fold CV\n",
    "print(\"Running grid search for the BaselineOnly algorithm ...\")\n",
    "# Fit the moviesdata to the model using the parameters of the grid search\n",
    "gs.fit(pda_dataset)\n",
    "# Save the best parameters of the models and the best scores\n",
    "results_table.append([\"PDA-Baseline\", '{:.3f}.'.format(gs.best_score[\"rmse\"]), '{:.3f}.'.format(gs.best_score[\"mae\"])])\n",
    "# Print out the the best RMSE, MAE and the respective model parameters\n",
    "print(\"\\nResults:\")\n",
    "print(\"Best RMSE:\", gs.best_score[\"rmse\"])\n",
    "print(\"Best params for RMSE\", gs.best_params[\"rmse\"])\n",
    "print(\"Best MAE:\", gs.best_score[\"mae\"])\n",
    "print(\"Best params for MAE\", gs.best_params[\"mae\"])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabulate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac2406e3a5a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display results of running the algorithms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults_table_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Recommender\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RMSE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MAE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_table_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtablefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pipe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tabulate' is not defined"
     ]
    }
   ],
   "source": [
    "# Display results of running the algorithms\n",
    "results_table_headers = [\"Recommender\", \"RMSE\", \"MAE\"]\n",
    "print(tabulate(results_table, results_table_headers, tablefmt=\"pipe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to a csv file\n",
    "results_df = pd.DataFrame(results_table, columns=[\"Recommender\", \"RMSE\", \"MAE\"])\n",
    "results_df.to_csv(\"../data/basic_algorithms_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
